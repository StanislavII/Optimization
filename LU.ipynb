{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdf35ec",
   "metadata": {},
   "source": [
    "# Линейные системы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed56d5",
   "metadata": {},
   "source": [
    "## Пролог"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e29077",
   "metadata": {},
   "source": [
    "Предположим, мы проводим некоторый эксперемент в котором участвует $n$ человек(наблюдения), также мы собираем некоторые характеристики(атрибуты) об этих людях (пусть их количество будет $m$). Таким образом $i$-ого человека можно описать вектором $a_i = (a_{i1}, a_{i2}, \\dots, a_{im})$, тогда уместить все наблюдения в компактной форме для глаз и написания можно в матричной форме, где $a_i$ будут являться строчками данной матрицы $A$, где $a_{ij}$ - элемент $i$-ой строчки (наблюдения), $j$-ого столбца. \n",
    "$\\newline$\n",
    "$$A = \\begin{bmatrix}\n",
    "    a_{11}       & a_{12} & a_{13} & \\dots & a_{1m} \\\\\n",
    "    a_{21}       & a_{22} & a_{23} & \\dots & a_{2m} \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{n1}       & a_{n2} & a_{n3} & \\dots & a_{nm}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Чаще всего нам будет удобно использовать обозначение $a_i$ для обозначение вектора столбца длины $n \\times  1$ $i$-го атрибута. В этом случае например линейную модель можно записать ввиде: $b = x_1 a_1 + \\dots x_m a_m$ (что эквивалентно матриченой форме $Ax = b$, где $x = (x_1, \\dots, x_m)^T, A = (a_1, \\dots, a_m)$). Размерности $A \\in \\mathbb{R}^{n \\times m}, b \\in \\mathbb{R}^{n \\times 1}, x \\in \\mathbb{R}^{m \\times 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367c256",
   "metadata": {},
   "source": [
    "### Где встречается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11a5cf",
   "metadata": {},
   "source": [
    "* Линейная регрессия\n",
    "* Задачи оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e423c",
   "metadata": {},
   "source": [
    "### Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6f992",
   "metadata": {},
   "source": [
    "$$\n",
    "Ax = b\n",
    "$$\n",
    "\n",
    "Дано: матрица $A_{n\\times m}$, вектор $b_{n\\times1}$\n",
    "\n",
    "Найти: вектор $x_{m\\times1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93b2d7",
   "metadata": {},
   "source": [
    "### Существование решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e9632",
   "metadata": {},
   "source": [
    "#### Теорема Кронекера-Капелли\n",
    "Система уравнений называется совместной, когда:\n",
    "\n",
    "$$\n",
    "\\textbf{rank}(A) = \\textbf{rank}(A|B)\n",
    "$$\n",
    "\n",
    "1. Если система несовместна, то решений **не существует**.\n",
    "2. Если система совместна и $\\textbf{rank}(A) = n$ - существует **единственное** решение.\n",
    "3. Если система совместна и  $\\textbf{rank}(A) < n$ - существует **бесконечное** количество решений.\n",
    "\n",
    "Таким образом, когда $\\textbf{rank}(A) = n$ матрица $A$ имеет полный ранг и решение существует.\n",
    "\n",
    "Также будем называть, когда $n = m$ - определенная система, $n > m$ - переопределенная система (в общем случае решений не имеет), $n < m$ - недоопределенная система (решение неединственно).\n",
    "\n",
    "На этой части рассмотрим базовые алгоритмы на определенных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7512b27",
   "metadata": {},
   "source": [
    "## Решаем линейные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e601bc",
   "metadata": {},
   "source": [
    "$$\n",
    "Ax = b \\rightarrow x = A^{-1}b\n",
    "$$\n",
    "\n",
    "Все.\n",
    "\n",
    "На самом деле нет. А почему нет?\n",
    "\n",
    "1. Получить обратную матрицу в общем случае дольше, чем работа других алгоритмов\n",
    "2. Сложность получения обратной матрицы $O(n^3)$, что сравнимо с альтерантивными алгоритмами, но в случае LU - алгоритм итеративный и при достижении разложения - алгоритм работает за $O(n^2)$\n",
    "3. Получение обратной матрицы - численно менее стабильный алгоритм \n",
    "4. Необходимо хранить обратную матрицу, в то время как итеративные алгоритмы in-place\n",
    "5. Иногда расчет $A^{-1}$ - оверкилл для получения решения, так как это не учитывает структуру матрицы \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2f8b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time in sec. inversion: 14.9, LU: 4.2, LU_sci: 4.3\n",
      "Error inv/lu_sc: 641.6 lu/lu_sc: 4.5 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu_factor, lu_solve\n",
    "from time import time\n",
    "\n",
    "A = np.random.rand(10_000,10_000)\n",
    "x = np.random.rand(10_000,1)\n",
    "b = A@x\n",
    "\n",
    "start = time()\n",
    "x_est = np.linalg.inv(A)@b\n",
    "\n",
    "error_inv = np.linalg.norm(x-x_est)\n",
    "time_inv = time() - start\n",
    "\n",
    "x_est_lu = np.linalg.solve(A,b)\n",
    "\n",
    "error_lu = np.linalg.norm(x-x_est_lu)\n",
    "time_lu = time() - start - time_inv\n",
    "\n",
    "lu, piv = lu_factor(A)\n",
    "x_est_lu_sc = lu_solve((lu, piv), b)\n",
    "\n",
    "error_lu_sc = np.linalg.norm(x-x_est_lu_sc)\n",
    "time_lu_sc = time() - start - time_lu - time_inv\n",
    "\n",
    "pct_inv = error_inv/error_lu_sc\n",
    "pct_lu = error_lu/error_lu_sc\n",
    "\n",
    "print(f'Time in sec. inversion: {time_inv:.1f}, LU: {time_lu:.1f}, LU_sci: {time_lu_sc:.1f}')\n",
    "print(f'Error inv/lu_sc: {pct_inv:.1f} lu/lu_sc: {pct_lu:.1f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447bff6",
   "metadata": {},
   "source": [
    "## Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c4f10",
   "metadata": {},
   "source": [
    "Начнем с того какие системы нам хотелось бы решать, или какие системы решать проще, то есть какого вида должна быть матрица $A$, чтобы система решалась простым методом подставновки.\n",
    "\n",
    "Напримир треугольная матрица.\n",
    "\n",
    "### Треугольные матрицы\n",
    "\n",
    "1. L - Lower triangular matrix (нижне треугольная матрица)\n",
    "\n",
    "\n",
    "$$ L = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & 0 & 0\\\\\n",
    "a_{21} & a_{22} & 0\\\\\n",
    "a_{31} & a_{32} & a_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "1. U - Upper triangular matrix (верхне треугольная матрица)\n",
    "\n",
    "$$ U =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13}\\\\\n",
    "0 & a_{22} & a_{23}\\\\\n",
    "0 & 0 & a_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Тогда, допустим следующая система решалась бы простым исключением переменных:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13}\\\\\n",
    "0 & a_{22} & a_{23}\\\\\n",
    "0 & 0 & a_{33}\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_3\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "{b_1}\\\\\n",
    "{b_2}\\\\\n",
    "{b_3}\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "x_{3}a_{33} = b_3 \\quad \\Rightarrow \\quad x_3^{*} = \\frac{b_3}{a_{33}} \\\\\n",
    "x_{2}a_{22} + x_3^{*}a_{23} = b_2 \\quad \\Rightarrow \\quad x_2^{*} = \\frac{b_2 - x_3^{*}a_{23}}{a_{22}} \\\\\n",
    "x_{1}a_{11}+ x_2^{*}a_{12} + x_3^{*}a_{13} = b_1 \\quad \\Rightarrow \\quad x_1^{*} = \\frac{b_1 - x_2^{*}a_{12} - x_3^{*}a_{13} }{a_{11}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Таким образом, система $N\\times N$ решается за $\\frac{N(N-1)}{2}$ вычетаний и умножений и $N$ делений, что похоже на $O(N^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc3d98",
   "metadata": {},
   "source": [
    "### Gaussian Elimination in matrix forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746851e",
   "metadata": {},
   "source": [
    "Метод исключения Гаусса основан на том, чтобы привести матрицу к такому виду. Метод Гаусса начинается с вычитания первой строки из остальных строк, чтобы занулить первый столбец, тем самым исключая переменную $x_1$ (определяя ее). Затем та же процедура повторяется для остальных столбцов.\n",
    "\n",
    "Данную процедуру можно описать путем умножения матриц, например:\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "4 & 4 & 2\\\\\n",
    "4 & 5 & 3\\\\\n",
    "2 & 3 & 3\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "Чтобы занулить первый столбец надо вычесть из 2 строчки первую 1 раз и 0.5 раз из 3 строчки вычесть первую, в матричной форме это записывается следующим образом.\n",
    "\n",
    "Если мы точно знаем какие операции нужно проводить для сведения матриц к треугольному (ступенчатому) виду, то можно воспользоваться следующим:\n",
    "> Домножая матрицу слевой стороны на единичную $\\mathbf{I}$, у которой на $(i, j)_{i \\neq j}$ позициях находятся элементы , которые обозначают следующие операции: \"вычти из $i$ строчки $j$ строчку\", если элемент $-m_{ij}$, и сложи строчки если $m_{ij}$\n",
    "\n",
    "В данной операции на месте $m_{21} = -1$, что означает вычитание из 2 строчки первой\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "M_{1}A =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "-1 & 1 & 0\\\\\n",
    "-0.5 & 0 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "4 & 4 & 2\\\\\n",
    "4 & 5 & 3\\\\\n",
    "2 & 3 & 3\n",
    "\\end{bmatrix}  = \n",
    "\\begin{bmatrix}\n",
    "4 & 4 & 2\\\\\n",
    "0 & 1 & 1\\\\\n",
    "0 & 1 & 2\n",
    "\\end{bmatrix} \\\\ \n",
    " \\newline\n",
    "M_{2}M_{1}A = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 1 & 0\\\\\n",
    "0 & -1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 & 4 & 2\\\\\n",
    "0 & 1 & 1\\\\\n",
    "0 & 1 & 2\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "4 & 4 & 2\\\\\n",
    "0 & 1 & 1\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix} = U\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "В итоге получаем,\n",
    "\n",
    "$$\n",
    "M_{2}M_{1}Ax = Ux = M_{2}M_{1}b\n",
    "$$\n",
    "\n",
    "Что уже решается делом техники, нужно лишь найти произведение $M_{2}M_{1}b$\n",
    "\n",
    "Также можно заметить, что $M_{2}M_{1}A = U$ можно переписать в $A = LU$, где $L = M_1^{-1}M_2^{-1}$\n",
    "\n",
    "$\n",
    "L = M_1^{-1}M_2^{-1} = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "1 & 1 & 0\\\\\n",
    "0.5 & 0 & 1\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 1 & 0\\\\\n",
    "0 & 1 & 1\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "1 & 1 & 0\\\\\n",
    "0.5 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Где все суб-диагональные элементы в $L$ это множители Гаусса, c которыми мы сталкнулись при процедуре исключения переменных. \n",
    "\n",
    "**Как правило $LU$ разложение и ассоциируется с методом Гаусса.**\n",
    "\n",
    "При получении $LU$ разложения остается только лишь дважды решить систему с треугольными матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209f777",
   "metadata": {},
   "source": [
    "## LU разложение\n",
    "\n",
    "**Теорема. Для любой матрицы $\\mathbf{A \\in \\mathbb{R}^{n\\times n}, \\mathbb{det}(A(1:k, 1:k))\\neq 0, k = 1:(n-1)}$ тогда существует нижнетреугольная матрица $\\mathbf{L \\in \\mathbb{R}^{n\\times n}}$ и верхнетреугольная матрица $\\mathbf{U \\in \\mathbb{R}^{n\\times n}}$, такие что $\\mathbf{A = LU}$, если матрица $\\mathbf{A}$ - невырождена, тогда разложение уникально и $\\mathbf{\\mathbb{det}(A) = u_{11}u_{22}\\dots u_{nn}}$.**\n",
    "\n",
    "* LU разложение считается самым дешевым матричным разложением $O(\\frac{2}{3}n^3)$\n",
    "### LU разложение, right-looking алгоритм \n",
    "\n",
    "$$\n",
    "A = LU \\\\\n",
    "A \\rightarrow \\begin{bmatrix}\n",
    "\\alpha_{11} & \\alpha_{12}^{\\top} \\\\\n",
    "\\alpha_{21}^{\\top} & A_{22} \n",
    "\\end{bmatrix}, L \\rightarrow \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "l_{21} & L_{22} \n",
    "\\end{bmatrix}, U \\rightarrow \\begin{bmatrix}\n",
    "u_{11} & u_{12}^{\\top} \\\\\n",
    "0 & U_{22} \n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "\\alpha_{11} & \\alpha_{12}^{\\top} \\\\\n",
    "\\alpha_{21}^{\\top} & A_{22} \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "u_{11} & u_{12}^{\\top} \\\\\n",
    "l_{21} & l_{21}u_{12}^{\\top} + L_{22}U_{22} \n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{cases}\n",
    "\\alpha_{11} = u_{11} \\\\\n",
    "a_{12}^{\\top} = u_{12}^{\\top} \\\\\n",
    "\\alpha_{21} = u_{11}l_{21} \\\\\n",
    "A_{22} - l_{21}u_{12}^{\\top} = L_{22}U_{22}\n",
    "\\end{cases} \\Rightarrow \\begin{cases}\n",
    "\\alpha_{21} \\leftarrow \\frac{\\alpha_{21}}{\\alpha_{11}} \\\\\n",
    "A_{22} \\leftarrow A_{22} - \\alpha_{21}\\alpha_{12}^{\\top}\n",
    "\\end{cases} \\rightarrow \\begin{cases}\n",
    "\\tilde \\alpha \\leftarrow \\dots \\\\\n",
    "A_{22} \\leftarrow \\dots\n",
    "\\end{cases} \\rightarrow \n",
    "\\begin{cases}\n",
    "\\tilde \\alpha \\leftarrow \\dots \\\\\n",
    "A_{nn} \\leftarrow \\dots\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$\\alpha_{21}$ размером $(n-k-1)$, тогда затраты на обновление $\\alpha_{21} \\leftarrow \\frac{\\alpha_{21}}{\\alpha_{11}}$ - $(n-k-1)$, затраты на само деление мало при росте $n$, $A_{22}$ размером $(n-k-1)\\times(n-k-1)$, тогда обновление матрицы требует $2(n-k-1)\\times(n-k-1)$ \n",
    "\n",
    "$\n",
    "\\sum_{k=0}^{n-1}2(n-k-1)^2 = \\sum_{j=0}^{n-1}2j^2 \\approx 2\\int_{0}^{n}x^2 \\,dx = \\frac{2}{3}n^3$\n",
    "* LU - не стабильный алгоритм. \n",
    "\n",
    "### PLU\n",
    "Нам нужны гарантии того, что ведущий элемент ненулевой, мы не делим на ноль.\n",
    "\n",
    "Например\n",
    "\n",
    "$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "2 & 2 & 5\\\\\n",
    "4 & 6 & 8\n",
    "\\end{bmatrix}, \\, M_1 = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "-2 & 1 & 0\\\\\n",
    "-4 & 0 & 1\n",
    "\\end{bmatrix}, \\, M_1A = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & 0 & 3\\\\\n",
    "0 & 2 & 4\n",
    "\\end{bmatrix}, \\quad \\text{алгоритм ломается, так как придется делить на 0}\n",
    "$\n",
    "\n",
    "Либо, $\\epsilon=0$\n",
    "\n",
    "$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "2 & 2 +\\epsilon & 5\\\\\n",
    "4 & 6 & 8\n",
    "\\end{bmatrix}, \\, M_1A = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & \\epsilon & 3\\\\\n",
    "0 & 2 & 4\n",
    "\\end{bmatrix}, \\, M_2 = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 1 & 0\\\\\n",
    "0 & -\\frac{2}{\\epsilon} & 1\n",
    "\\end{bmatrix}, \\, M_2M_1A = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & \\epsilon & 3\\\\\n",
    "0 & 0 & 4 - \\frac{6}{\\epsilon}\n",
    "\\end{bmatrix}, \\, L = M_1^{-1}М_2^{-1} = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "2 & 1 & 0\\\\\n",
    "4 & \\frac{2}{\\epsilon} & 1\n",
    "\\end{bmatrix}\\\\\n",
    "\\newline\n",
    "\\epsilon > 0 \\, (small) \\rightarrow (4 - \\frac{6}{\\epsilon}) \\rightarrow - \\frac{6}{\\epsilon} \\\\\n",
    "\\tilde U = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & \\epsilon & 3\\\\\n",
    "0 & 0 &  - \\frac{6}{\\epsilon}\n",
    "\\end{bmatrix}, \\, \\tilde L \\tilde U = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "2 & 2 +\\epsilon & 5\\\\\n",
    "4 & 6 & 4\n",
    "\\end{bmatrix} \\neq A\n",
    "$\n",
    "\n",
    "А что, если бы мы могли как нибудь поменять местами строчки, например $2\\longleftrightarrow3$, данная операция выплняется через следующее матричное умножение:\n",
    "> умножая на единичную матрицу $(i,j)_{i=j} = 1$ матрица не меняется, умножение в таком виде говорит нам о том, что $i$-ая строчка находится в $j$-ом индексе, но если переставить единицы по строчкам то получится и смена строчек после умножения\n",
    "\n",
    "Сейчас мы хотим переставить 2 и 3 строчки, тогда $1$ из 2 строчки единичной матрицы должна стоять в 3 столбце, а 1 из 3 строчки единичной матрицы должна стоять во 2 столбце. **Такие матрицы называются матрицами перестановок со свойством** $\\mathbf{P^{-1} = P^{\\top}}$\n",
    "\n",
    "$\n",
    "P_1M_1A = \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 0 & 1\\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & 0 & 3\\\\\n",
    "0 & 2 & 4\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & 2 & 4\\\\\n",
    "0 & 0 & 3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Идея состоит в том чтобы на шаге $k$ найти максимальный элемент в столбце под текущей переменной $x_k$ и поменять эту строчку $k$ со строкой, которая содержит $x_{max_k}$\n",
    "\n",
    "Общий вывод PLU разложения:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "& \\text{Solution of} \\, Ax = b, \\, \\text{where} \\\\\n",
    "& PA = LU \\\\\n",
    "& \\textbf{Step 1.} \\, LUx = P^{\\top}b \\\\\n",
    "& \\textbf{Step 2.} \\, Ly = \\tilde b \\\\\n",
    "& \\textbf{Step 3.} \\, Ux = y\\\\\n",
    "& \\textbf{Step 4.} \\, \\tilde x\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "& \\text{Solution of} \\, Ax = b, \\, \\text{where} \\\\\n",
    "& PAQ^{\\top} = LU \\\\\n",
    "& \\textbf{Step 1.} \\, LUx = P^{\\top}b\\\\\n",
    "& \\textbf{Step 2.} \\, Lz = \\tilde b \\\\\n",
    "& \\textbf{Step 3.} \\, Uy = z \\\\\n",
    "& \\textbf{Step 4.} \\, \\tilde x = Q^{\\top}y\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "**LU Теорема. Для каждой матрицы полного ранга** $\\mathbf{R^{n\\times n}}$ **существует матрица перестановок P, такая что матрица PA может быть представлена через LU разложение, где L - нижне тругольная матрица со всеми диагональными элементами 1**\n",
    "\n",
    "**Доказательство:**\n",
    "\n",
    "Если матрица полного ранга то с помощью перестановки\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "& P_1A = \\begin{bmatrix}\n",
    "a_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22} \n",
    "\\end{bmatrix},(a_{11}\\neq0), P_1A= \\begin{bmatrix}\n",
    "1 & 0\\\\\n",
    "\\frac{A_{21}}{a_{11}} & \\mathbf{I} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a_{11} & A_{12}\\\\\n",
    "0 & S \n",
    "\\end{bmatrix}\\\\\n",
    "& S = A_{22} - a_{11}^{-1}A_{21}A_{12} \\\\\n",
    "& \\mathbb{det}(A)\\neq 0, \\mathbb{det}(S)\\neq 0, \\, \\text{продолжаем разложение по индукции для S}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Где $S$ является дополнением Шура матрицы $A$ к элементу $A_{22}$, дополнение Шура играет ключевую роль в алгоритмических приложениях для решения блочных систем уравнений методом Гаусса/LU разложением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4d493",
   "metadata": {},
   "source": [
    "### Блочный метод Гаусса\n",
    "\n",
    "Бывает удобным представление выражения метода Гаусса как обновление под-матриц исходной матрицы, на каждом шаге метода Гаусса нижняя замыкающая под-матрица называется **дополнением Шура.**\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} \\\\\n",
    "A_{21} & A_{22}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "L_{11} & 0 \\\\\n",
    "L_{21} & L_{22}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "U_{11} & U_{12} \\\\\n",
    "0 & U_{22}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "L_{11}U_{11} & L_{11}U_{12} \\\\\n",
    "L_{21}U_{11} & L_{22}U_{22} + L_{21}U_{12}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Также иногда записывается в эквивалентной записи:\n",
    "\n",
    "$$\n",
    "A \\in \\mathbb{R}^{n \\times n}, A_{11} \\in \\mathbb{R}^{r \\times r}, A_{12} \\in \\mathbb{R}^{r \\times (n-r)},  A_{21} \\in \\mathbb{R}^{(n-r) \\times r}, A_{22} \\in \\mathbb{R}^{(n-r) \\times (n-r)}\\\\\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} \\\\\n",
    "A_{21} & A_{22}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "L_{11} & 0 \\\\\n",
    "L_{21} & \\mathbf{I}_{n-r}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf{I}_{r} & 0 \\\\\n",
    "0 & S\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "U_{11} & U_{12} \\\\\n",
    "0 & \\mathbf{I}_{n-r}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$\n",
    "U_{12} = L_{11}^{-1}A_{12} \\\\\n",
    "L_{21} = A_{21}U_{11}^{-1} \\\\ \n",
    "L_{22}U_{22} = A_{22} - L_{21}U_{11}^{-1}L_{11}^{-1}A_{12} = A_{22} - A_{21}A_{11}^{-1}A_{12} \\\\\n",
    "S =  A_{22} - A_{21}A_{11}^{-1}A_{12} - \\, \\text{Блочный вариант обновления в методе Гаусса}\n",
    "$\n",
    "\n",
    "Либо еще одно свойство, если $det(A), det(A_{11}) \\neq 0$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} \\\\\n",
    "A_{21} & A_{22}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "X \\\\\n",
    "S^{-1} \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\mathbf{I} \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb246a",
   "metadata": {},
   "source": [
    "```python\n",
    "def block_lu_decomposition(A):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a2cf1",
   "metadata": {},
   "source": [
    "### Ремарка про существование и единственность LU разложения \n",
    "\n",
    "Как правило за существование и единственность $LU$ разложения отвечает сингулярность матрицы и равенство нулю ведущих миноров. Что вообще означает уникальность и в чем оно проявляется? Тут пример.\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 3 \\\\\n",
    "1 & 4 & 0 \\\\\n",
    "3 & 5 & 3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0.5 & 1 & 0 \\\\\n",
    "1.5 & 1 & 1\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "2 & 1 & 3 \\\\\n",
    "0 & 3.5 & -1.5 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Это $LU$ разложение матрицы с линейно-зависимой 3 строчкой, сумма первой и второй строчки равна третьей, следовательно матрица не обладает полным рангом, ранг = 2, а в матрице $U$ на диагонали появляется нулевой элемент, таким образом мы можем назначить $l_{33} = *$ - абсолютно любым. Таким образом разложение для данной матрицы не существует единственного разложения. \n",
    "\n",
    "$LU$ - разложение является численным алгоритмом получения произведения треугольных матриц, например можно разложить:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "1 & 1  \\\\\n",
    "1 & 1 \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0  \\\\\n",
    "1 & 1 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 1  \\\\\n",
    "0 & 0 \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0 & 0  \\\\\n",
    "0 & 0 \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0  \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "0 & 0  \\\\\n",
    "0 & 0 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09386db",
   "metadata": {},
   "source": [
    "### LU на прямоугольных матрицах\n",
    "\n",
    "Нетрудно показать, что LU разложение может быть произведено и над матрицами $A \\in \\mathbb{R}^{n \\times r}, n > r$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "3 & 1 \\\\\n",
    "5 & 2 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "0 & -2 \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "A \\in \\mathbb{R}^{r \\times n}, r < n \\\\\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "4 & 1 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "0 & -3 & -6\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49743327",
   "metadata": {},
   "source": [
    "### Parallel LU\n",
    "> Блок о том как считать блочный LU параллельно "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819945c2",
   "metadata": {},
   "source": [
    "### LU для симметричных матриц\n",
    "\n",
    "Если матрица симметричная, то существует связь между матрицами $L$ и $U$, например:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{c}{a} & 1 \n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "a & c \\\\\n",
    "0 & d - (\\frac{c}{a})c \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{c}{a} & 1 \n",
    "\\end{bmatrix}(\\begin{bmatrix}\n",
    "a & 0 \\\\\n",
    "0 & d - (\\frac{c}{a})c \n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1 & \\frac{c}{a} \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix})\n",
    "$\n",
    "\n",
    "Получается, что $U$ это скалированная построчно $L^{\\top}$\n",
    "\n",
    "### LDL разлоложение \n",
    "\n",
    "**Теорема. Eсли $\\mathbf{A \\in R^{n\\times n}}$ матрица симметрична и ее главные миноры не вырождены,  то существует такая нижне треугольная матрица L и диагональная матрица D, что**\n",
    "\n",
    "$\\mathbf{A = LDL^{\\top}}$\n",
    "\n",
    "**При этом разложение единственно**\n",
    "\n",
    "Существует классическое **скалярное произведение** $<x, y> = x^{\\top}y$, также можно вывести его обощенную форму $<x, y> = x^{\\top}Sy$, $S$ - единичная матрица $\\mathbf{I}_n$\n",
    "\n",
    "Если применить **процесс Грамма-Шмидта** по преобразованию **базиса** $(e_1,e_2, \\dots, e_n) \\rightarrow (v_1,v_2, \\dots, v_n)$ который ортогонален относительно операции обобщенного скалярного произведения, то мы получим $LDL^{\\top}$ разложение, в общем, данное разложение является процесс Грамма-Шмидта примененного к скалярному произвдеению.\n",
    "\n",
    "Пример:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S &= \\begin{bmatrix}\n",
    "4 & 1 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix} \\\\\n",
    "e = (e_1, e_2) &= \\begin{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\end{pmatrix} \\\\\n",
    "v_1 &= e_1 \\\\\n",
    "v_2 &= e_2 - \\frac{<e_2, v_1>}{<v_1, v_1>}v_1 \\\\\n",
    "<e_2, v_1> = e_2^{\\top}Sv_1 &= \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\begin{bmatrix}\n",
    "4 & 1 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1 \\\\\n",
    "<v_1, v_1> = v_1^{\\top}Sv_1 &= \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{bmatrix}\n",
    "4 & 1 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 4 \\\\\n",
    "v_2 &= \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}  - \\frac{1}{4}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} =  \\begin{pmatrix} -\\frac{1}{4} \\\\ 1 \\end{pmatrix}\\\\\n",
    "v = (v_1,v_2)  &= \\begin{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{4} \\\\ 1 \\end{pmatrix} \\end{pmatrix} \\\\\n",
    "L_0v = e, L_0 = v^{-1}e &= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{1}{4} & 1\n",
    "\\end{bmatrix} \\\\\n",
    "D_1 &= <v_1, v_1> = 4 \\\\\n",
    "D_2 &= <v_2, v_2> = \\begin{pmatrix} -\\frac{1}{4} & 1 \\end{pmatrix} \\begin{bmatrix}\n",
    "4 & 1 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\\begin{pmatrix} -\\frac{1}{4} \\\\ 1 \\end{pmatrix} = \\frac{11}{4} \\\\\n",
    "S = LDL^{\\top} &= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{1}{4} & 1\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "4 & 0 \\\\\n",
    "0 & \\frac{11}{4}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1 & \\frac{1}{4} \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Это работает для всех симметричных матриц, для несимметричных работает схожее по смыслу и реализации $\\mathbf{LDU}$ разложение\n",
    "\n",
    "### Разложение Холецкого\n",
    "\n",
    "Если матрица является симметричной, а еще и положительно определенной тогда в разложениие $A=LDL^{\\top}$, матрицы $A, D$ обладают одинаковой **инерцией**, тогда мы можем записать $A=LDL^{\\top} = (LD^{\\frac{1}{2}})(LD^{\\frac{1}{2}})^{\\top} = \\tilde L\\tilde L^{\\top}$, а матрица $\\tilde L$ называется **Cholesky factor**.\n",
    "\n",
    "**Теорема. Для любой $\\mathbf{A \\in \\mathbb{R}^{n \\times n}}$ - симметричной и положительно определенной матрицы существует уникальная нижнетреугольная матрица $\\mathbf{L}$ с положительным диагональными элементами, такая что $\\mathbf{A = LL^{\\top}}$**\n",
    "\n",
    "**Теорема. Если матрица положительно определеная то в $\\mathbf{LU}$ разложении диагональные элементы матрицы $\\mathbf{U}$ положительные.**\n",
    "\n",
    "Доказательство:\n",
    "\n",
    "Если вспомнить свойства симметричных матриц, матрицы $A$ и $B^{\\top}AB$ обладают одинаковой инерцией, тогда в случае положительно определенных матриц $X = B^{\\top}AB$ также является положительно определенной. Тогда $A = LU$, $B = (L^{-1})^{\\top} = L^{-\\top}$, $X = L^{-1}LUL^{-T} = UL^{-\\top}$ - положительно определена (положительные элементы на диагонали), следовательно на диагонали у матрицы $U$ также расположены положительные элементы на диагонали это вытекает из того, что матрица $L^{-\\top}$ верхнетреугольная матрица с единицами на диагонали и $x_{ii} = u_{ii}$.\n",
    "\n",
    "### LDL разложение с поворотами\n",
    "\n",
    "Если симметричная положительно-определенная система плохо приводится к ступенчатому виду, как и в случае с $LU$ разложением мы можем производить умнржение на матрицы, меняя местами строчки или столбцы, если матрица $A$ - симметричная, то матрица $P_1A$ - несимметричная, где матрица $P_1$ - матрица перестановок, c другой стороны матрица $P_1AP_1^{\\top}$ - симметричная, что приводит к следующему разложению:\n",
    "\n",
    "$$\n",
    "P_1AP_1^{\\top} = \\begin{bmatrix}\n",
    "\\alpha & v^{\\top} \\\\\n",
    "v & B\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{v}{\\alpha} & \\mathbb{I}_{n-1}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\alpha & 0 \\\\\n",
    "0 & \\tilde A\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{v}{\\alpha} & \\mathbb{I}_{n-1}\n",
    "\\end{bmatrix}^{\\top}\n",
    "$$\n",
    "\n",
    "Где $\\tilde A$ - известное нам **дополнение Шура**, $\\tilde A = B - \\frac{vv^{\\top}}{\\alpha}$, и проведя рекурссивно разложение и для $\\tilde P\\tilde A \\tilde P^{\\top} = \\tilde L \\tilde D \\tilde L^{\\top}$ получим общее разложение:\n",
    "\n",
    "$$\n",
    "PAP^{\\top} = LDL^{\\top} \\\\\n",
    "P = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & \\tilde P\n",
    "\\end{bmatrix}, L = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{v}{\\alpha} & \\tilde L\n",
    "\\end{bmatrix}, D = \\begin{bmatrix}\n",
    "\\alpha & 0 \\\\\n",
    "0 & \\tilde D\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4397d2",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "1. $A = LU$ - разложение матрицы $A$ с оригинальным расположение строк и столбцов на нижнетреугольную матрицу $L$ и верхнетреугольную матрицу $U$\n",
    "2. Без правильного упорядочения или перестановок в матрице, разложение может не считаться (технически), так как ведущий диагональный элемент на каждой итерации не должен равняться 0, эта проблема решается домножением на матрицу перестановок строчек на каждой итерации $PA = LU$ либо $PAQ = LU$ перестановкой и строчек и столбцов\n",
    "3. Любая матрица $A$ допускает $PLU$ разложение. Если матрица $A$ обратима, то сущетсвует $LU$ разложение только тогда, когда все главные миноры матрицы не равны 0.\n",
    "4. Если $A$ — сингулярная матрица ранга $K$, то она допускает $LU$ -факторизацию первых ведущих $k$ миноров, хотя обратное неверно.\n",
    "5. Для матрицы $A$ также существует уникальное $A = LDU$ разложение с единицами на главных диагоналях матриц $L,U$ и $D$ - диагональная матрица.  В этом случае $LU$-разложение также будет уникальным, если мы потребуем, чтобы диагональ $L$ или $U$ состояла из единиц. Если матрица $A$ - симметрична, то это разложение превращается в $A = LDL^{\\top}$.\n",
    "6. Если матрица $A$ - симметрична и положительно определена, то существует следующее уникальное разложение, которое называется разложением Холецкого $A = \\tilde L \\tilde L^{\\top}$.\n",
    "7. $LU$ разложение по сути представляет собой модифицированную форму метода Гаусса.\n",
    "8. $LU$ разложение используется для решение систем уравнений вида $Ax = b$ в три шага. Получение разложения $A = P^{-1}LU \\rightarrow LUx = Pb$. Решение треугольной системы $Ly = Pb$. Решение треугольной системы $Ux = y$. Решение треугольной системы приблизительное можно оценить в $O(n^2)$, $PLU$ - разложение в $O(\\frac{2}{3}n^3)$. Следовательно, весь алгоритм решения $Ax = b$ через $PLU$ разложение оценивается в $O(\\frac{2}{3}n^3)$.\n",
    "9. $LU$ разложение может быть неуникальным и для обратимых матриц с ненулевыми главными минорами, если в алгоритме разложения нету ограничение на диагональ матрицы $L$, в базовом $LU$ представлении на диагонали стоят единицы, если мы будем искать решение задачи на всем пространстве, то в полученном разложении всегда можем сделать следующую операцию $\\alpha L\\frac{1}{\\alpha}U$"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Desktop/Python/Optimization/Untitled.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
